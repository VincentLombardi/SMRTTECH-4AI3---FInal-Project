{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from path import *\n",
    "\n",
    "# collects the save 1% random sample of data from the saved csv files and saves all data frames in a list\n",
    "dfs = []\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        dfs.append(pd.read_csv(path + \"/\" + file))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = []\n",
    "y = []\n",
    "# data gets scaled and split into features and labels\n",
    "for df in dfs:\n",
    "    temp_features = scaler.fit_transform(df.drop(['label'], axis=1))\n",
    "    X.append(temp_features)\n",
    "    temp_label = df['label']\n",
    "    y.append(temp_label)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 1.77736932,  0.58503372,  0.17457166,  1.47813761,  1.0287388 ,\n         0.10920603, -0.35894874],\n       [-0.75346763, -0.57133758, -0.0863961 ,  1.42957144,  0.97517145,\n         0.02669629, -0.24064874],\n       [ 0.57921512,  0.59773999,  0.104731  ,  1.42498408,  0.91202783,\n         0.12298785, -0.55046148],\n       [ 0.25739087, -0.39029823, -0.0734617 ,  1.40085058,  0.81792753,\n         0.07365867,  0.25740449],\n       [-0.30873563,  0.28695912,  0.01378386,  1.35946462,  0.77180841,\n         0.07376059, -0.46822903],\n       [ 1.48973746,  0.07045823,  0.08022641,  1.41521101,  0.82966513,\n         0.11852603, -0.12644887],\n       [-0.90965519, -0.08251414,  0.02231159,  1.37272808,  0.80725396,\n         0.05740812, -0.52587762],\n       [ 1.90455112,  0.43151269,  0.24827512,  1.45918982,  0.98285243,\n         0.15128758, -0.20130896],\n       [-0.95163327, -0.55205613,  0.05340194,  1.35627342,  0.82474398,\n         0.0239671 , -0.3204228 ],\n       [ 1.51688344,  0.67816054,  0.24689268,  1.69833085,  1.88378796,\n         0.10990814, -0.44295481]])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000000, 8)\n",
      "(12000000, 8)\n",
      "(12250000, 8)\n",
      "(11750000, 8)\n",
      "(11750000, 8)\n",
      "(11250000, 8)\n",
      "(12250000, 8)\n",
      "(12250000, 8)\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    print(df.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "#train_test_split the data --> I think test_size = 0.0001 (0.01%) should be good since we have such a huge data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = [], [], [], []\n",
    "for i in range(len(X)):\n",
    "    X_train_temp, X_test_temp, y_train_temp, y_test_temp = train_test_split(X[i], y[i], test_size=0.0001,random_state=3)\n",
    "    X_train.append(X_train_temp)\n",
    "    X_test.append(X_test_temp)\n",
    "    y_train.append(y_train_temp)\n",
    "    y_test.append(y_test_temp)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# merge the testing data into one data set\n",
    "test_X = pd.DataFrame()\n",
    "test_y = pd.DataFrame\n",
    "for df in X_test:\n",
    "    print(type(df))\n",
    "    # test_X = pd.concat(df)\n",
    "# for df in y_test:\n",
    "#     test_y = pd.concat(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
